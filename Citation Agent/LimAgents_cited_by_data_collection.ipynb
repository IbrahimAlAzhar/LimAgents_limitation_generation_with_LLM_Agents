{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c27e5960-5169-4f06-a9cf-72276ee299dc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"df_neurips_limitation_and_OR_with_cited_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ee10dac-b845-4d13-b790-f69a585d6d89"
      },
      "source": [
        "openAlex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_openalex_id_short(title: str) -> str | None:\n",
        "    \"\"\"Search OpenAlex by title and return the short ID, or None if not found.\"\"\"\n",
        "    resp = requests.get(\n",
        "        \"https://api.openalex.org/works\",\n",
        "        params={\"filter\": f\"title.search:{title}\", \"per-page\": 1}\n",
        "    )\n",
        "    resp.raise_for_status()\n",
        "    results = resp.json().get(\"results\", [])\n",
        "    if results:\n",
        "        return results[0][\"id\"].rsplit(\"/\", 1)[-1]\n",
        "    return None\n",
        "\n",
        "def fetch_citers(openalex_id_short: str) -> list[dict]:\n",
        "    \"\"\"Given a short OpenAlex ID, return a list of {'title', 'doi'} for each citing work.\"\"\"\n",
        "    if not openalex_id_short:\n",
        "        return []\n",
        "    resp = requests.get(\n",
        "        \"https://api.openalex.org/works\",\n",
        "        params={\n",
        "            \"filter\":   f\"referenced_works:{openalex_id_short}\",\n",
        "            \"per-page\": 200\n",
        "        }\n",
        "    )\n",
        "    resp.raise_for_status()\n",
        "    citers = resp.json().get(\"results\", [])\n",
        "    return [\n",
        "        {\"title\": c[\"display_name\"], \"doi\": c.get(\"doi\")}\n",
        "        for c in citers\n",
        "    ]\n",
        "\n",
        "# Prepare the column\n",
        "df['cited_by'] = None\n",
        "\n",
        "# Loop and assign in-place\n",
        "for idx, row in df.iterrows():\n",
        "    title = row['df_title']\n",
        "    oa_id = get_openalex_id_short(title)\n",
        "    citers = fetch_citers(oa_id)\n",
        "    df.at[idx, 'cited_by'] = citers\n",
        "    print(f\"Row {idx}: found {len(citers)} citers for '{title}'\")\n"
      ],
      "metadata": {
        "id": "WZ1Ue6Ys4DC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_openalex_id_short(title: str) -> str | None:\n",
        "    resp = requests.get(\n",
        "        \"https://api.openalex.org/works\",\n",
        "        params={\"search\": title, \"per-page\": 1}\n",
        "    )\n",
        "    resp.raise_for_status()\n",
        "    results = resp.json().get(\"results\", [])\n",
        "    if results:\n",
        "        return results[0][\"id\"].rsplit(\"/\", 1)[-1]\n",
        "    return None\n",
        "\n",
        "def fetch_citers(openalex_id_short: str) -> list[dict]:\n",
        "    if not openalex_id_short:\n",
        "        return []\n",
        "    resp = requests.get(\n",
        "        \"https://api.openalex.org/works\",\n",
        "        params={\"filter\": f\"referenced_works:{openalex_id_short}\", \"per-page\": 200}\n",
        "    )\n",
        "    resp.raise_for_status()\n",
        "    return [\n",
        "        {\"title\": c[\"display_name\"], \"doi\": c.get(\"doi\")}\n",
        "        for c in resp.json().get(\"results\", [])\n",
        "    ]\n",
        "\n",
        "# ensure the column exists\n",
        "df['cited_by'] = df.get('cited_by', None)\n",
        "\n",
        "# only iterate rows from index 102 onward\n",
        "for idx in df.index[df.index >= 102]:\n",
        "    title = df.at[idx, 'df_title']\n",
        "    oa_id  = get_openalex_id_short(title)\n",
        "    citers = fetch_citers(oa_id)\n",
        "    df.at[idx, 'cited_by'] = citers\n",
        "    print(f\"Row {idx}: found {len(citers)} citers\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AiVxVeU94FPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aa0c771-6cd1-4b33-8b29-121a367873a8"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"df_neurips_limitation_and_OR_with_cited_data.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc66b256-fa9e-4b37-a243-ad215f157482"
      },
      "source": [
        "arxiv dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f20ec8a7-e56d-4e6f-b5c0-bf06e5b6929e",
        "outputId": "d249191c-0640-4c8c-d72a-cfe7b6bbc25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2760558 records loaded\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "\n",
        "data = []\n",
        "with open(\n",
        "    \"/media/ibrahim/Extreme SSD/Limitations Data/arxiv_metadata/arxiv-metadata-oai-snapshot.json\",\n",
        "    \"r\", encoding=\"utf-8\"\n",
        ") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        # parse each JSON object\n",
        "        obj = json.loads(line)\n",
        "        data.append(obj)\n",
        "\n",
        "# now `data` is a list of dicts\n",
        "print(len(data), \"records loaded\")\n",
        "\n",
        "# turn your list of dicts into a DataFrame\n",
        "df_arxiv = pd.DataFrame(data)\n",
        "\n",
        "# a) CSV\n",
        "df_arxiv.to_csv(\"arxiv_metadata.csv\", index=False)\n",
        "print(\"Saved to arxiv_metadata.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ee199eb-3e33-4d3e-8f04-619683a3f8fe",
        "outputId": "c68ff2cd-a6c8-4374-88d2-f5076b79342e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7220/920707665.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_arxiv = pd.read_csv(\"/media/ibrahim/Extreme SSD/Limitations Data/arxiv_metadata/arxiv_metadata.csv\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_arxiv = pd.read_csv(\"arxiv_metadata.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e7e31a8-b1f2-4add-a75c-405b9f505806"
      },
      "source": [
        "collect cited papers from arxiv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure df['cited_by'] already exists and df_arxiv has 'title' and 'id'\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    citers = row.get('cited_by') or []      # list of dicts\n",
        "    for citer in citers:\n",
        "        title_to_find = citer.get('title')\n",
        "        arxiv_id = None\n",
        "        # scan every row in df_arxiv for a matching title\n",
        "        for _, arxiv_row in df_arxiv.iterrows():\n",
        "            if arxiv_row['title'] == title_to_find:\n",
        "                arxiv_id = arxiv_row['id']\n",
        "                print(f\"Row {idx}: matched '{title_to_find}' â†’ arXiv ID {arxiv_id}\")\n",
        "                break\n",
        "        # add the new key (will be None if no match)\n",
        "        citer['arxiv_id'] = arxiv_id\n",
        "\n",
        "    # write the updated list of dicts back into df\n",
        "    df.at[idx, 'cited_by'] = citers\n",
        "\n",
        "# now each dict in df['cited_by'] has an 'arxiv_id' key\n",
        "# print(df[['df_title','cited_by']].head())\n",
        "df.to_csv(\"df_neurips_limitation_and_OR_with_cited_data.csv\",index=False)"
      ],
      "metadata": {
        "id": "wcaGWwtG4OkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}