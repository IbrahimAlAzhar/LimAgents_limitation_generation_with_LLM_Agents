{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"df.csv\")"
      ],
      "metadata": {
        "id": "mgqNo4Z7Kxvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['response_string'] = df.apply(lambda row: f\"\"\"Abstract: {row['Abstract']}\n",
        "Introduction: {row['Introduction']}\n",
        "Related_Work: {row['Related_Work']}\n",
        "Methodology: {row['Methodology']}\n",
        "Dataset: {row['Dataset']}\n",
        "Conclusion: {row['Conclusion']}\n",
        "\"\"\", axis=1)"
      ],
      "metadata": {
        "id": "ex3ck7GuKKT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "generated_summary = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful, respectful, and honest assistant for generating limitations or shortcomings of a research paper.\n",
        "    I am providing 'Abstract', 'Introduction', 'Related_Work', 'Methodology', 'Dataset' and\n",
        "    'Conclusion' of a scientific paper.\n",
        "    Generate limitations based on these texts. \\n{df['response_string'][i]}\n",
        "    \"\"\"\n",
        "\n",
        "    summary_text = \"\"\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        stream=True,\n",
        "        temperature=0.1  # Adjust the temperature as needed, max_tokens=150\n",
        "    )\n",
        "\n",
        "    for chunk in stream:\n",
        "        summary_chunk = chunk.choices[0].delta.content or \"\"\n",
        "        # print(limitation_chunk, end=\"\")\n",
        "        summary_text += summary_chunk\n",
        "\n",
        "    summary_chunks = []\n",
        "    summary_chunks.append(summary_text)\n",
        "    generated_summary.append(summary_chunks)\n",
        "    time.sleep(7)\n"
      ],
      "metadata": {
        "id": "Fz3LxEILKKJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_fASglWKKCg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}